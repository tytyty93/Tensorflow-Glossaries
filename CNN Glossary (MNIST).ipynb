{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                  DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing MNIST\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# from tensorflow.keras.datasets import mnist ---> Do note that MNIST has already been incorporated into Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train,y_train), (x_test,y_test) = mnist.load_data() ---> Do note that the x_train and x_train has already been organised\n",
    "#                                                             MNIST dataset. Don't need to do splits\n",
    "\n",
    "# x_train.shape ---> This will output(60000, 28, 28). This means that x_train has 60,000 images and each images is 28 by 28 pixels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_image = x_train[0]\n",
    "# single_image ---> This will output the raw values inside that single image in the form of an array.\n",
    "#              ---> Basically outputs 28 arrays containing 28 numbers inside which forms the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying the image using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(single_image) ---> This will display the 2D array object. The default color is viridis(Purple(0) to Yellow(255))\n",
    "# plt.imshow(single_image, cmap = 'binary') ---> This will display the image from colors white(0) to grey(255)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                              Converting y_train and y_test to Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train ---> This is just a single array with 60,000 labels. So for y_train[0], it will be number 5. This is also\n",
    "#              the number displayed in x_train[0]\n",
    "\n",
    "# Do note that these are categories. If we pass in the labels directly for training, the model will predict decimals \n",
    "# as they will think that it is a continuous value. We need to let the network know that it is a classification problem\n",
    "# and that the number 5 is a category.\n",
    "\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# new_varible_name = to_categorical(y_train) ---> This will convert the y_train into arrays of (60000, 10)\n",
    "#                                        ---> If we do enter new_variable_name, it will output an array of (1 row, 10 columns)\n",
    "#                                        ---> new_variable_name[0] will output 1 at position 6 to represent 5 while rest are 0\n",
    "\n",
    "\n",
    "# Perform the conversion for y_train and y_test\n",
    "\n",
    "# y_cat_test = to_categorical(y_test, num_classes = 10)\n",
    "# y_cat_train = to_categorical(y_train, num_classes = 10)\n",
    "\n",
    "# [Do note that the num_classes is just to specify how many classes are there. If we do not put, it will determine by itself\n",
    "# how many classes there are by the number of unique values in y label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                          Normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train/255\n",
    "# x_test = X_test/255\n",
    "\n",
    "# [We do not have to use the MinMax Scaler as we already know what the maximum value is for this(255)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                         Reshaping the x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to let the network know that we only have a single image color channel from 0 to 1\n",
    "\n",
    "# x_train = x_train.reshape(60000,28,28,1) ---> 60000 images, 28 width, 28 height, 1 color_channel\n",
    "# x_test = x_test.reshape(10000, 28, 28, 1) ---> 10000 images, 28 width, 28 height, 1 color_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                               Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Sequential and Dense\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "#                                             Convolution Layer\n",
    "\n",
    "# model.add(Conv2D(filters = 128, kernel_size=(4,4), input_shape=(28,28,1), activation = 'relu'))\n",
    "\n",
    "# Filters: The larger the image, the larger the filter should be. Should be in powers of 2s.\n",
    "\n",
    "# Kernal_size: Typical sizes are 2 by 2 or 4 by 4\n",
    "\n",
    "# Strides: How many pixels do you want to move the kernal, for larger images, should have bigger strides\n",
    "\n",
    "# Padding='valid': Applied by default. Doesn't apply any padding. If the kernal size fits perfectly with the image pixels \n",
    "#                    and the strides, there is no need  for it. Eg; 28pixels image divided by 4x4 kernal \n",
    "#                    gives integer so can set as valid  \n",
    "\n",
    "# Padding='same': Automatically figures out what the padding should be so that the image gets fully covered by \n",
    "#                    the filter and stride. Ensures that the output size is the same as input.\n",
    "\n",
    "# Input shape: The shape of a single image\n",
    "\n",
    "\n",
    "#                                                Pooling Layer\n",
    "\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# The pool_size is already set as 2 by 2 by default so actually don't have to set one\n",
    "\n",
    "\n",
    "\n",
    "#                                            Flattening the image\n",
    "\n",
    "# Essentially means taking the width and height(28 by 28 in this example) and flatten it into a single array(28*28 = 784 in\n",
    "# this example.)\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "\n",
    "#                                   Adding the Dense Layer & Output Neurons\n",
    "\n",
    "# model.add(Dense(128, activation='relu')) ---> Should more or less match the same scale as the flattened unit and in powers of 2\n",
    "\n",
    "# model.add(Dense(10, activation = 'softmax')) ---> The final layer should have 1 neuron per class(10 for this example)\n",
    "#                                              ---> For multi-classification, should be using softmax activation\n",
    "\n",
    "\n",
    "#                                                    Compile\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#                                             Training the model\n",
    "\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# early_stop = EarlyStopping(monitor = 'val_loss', patience=1)\n",
    "\n",
    "# model.fit(x_train, y_cat_train, epochs=10, validation_data=(x_test, y_cat_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                               Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = pd.DataFrame(model.history.history)\n",
    "# metrics ---> This will output the loss, accuracy, val_loss, val_accuracy based on the example above\n",
    "\n",
    "# model.metrics_names ---> Shows what are the metrics the model produces which you've specified before. Eg; accuracy, val_loss\n",
    "\n",
    "# metrics[['loss', 'val_loss']].plot() ---> Plots the loss against val_loss\n",
    "# metrics[['accuracy', 'val_accuracy']].plot() ---> Plots the accuracy against val_accuracy\n",
    "\n",
    "\n",
    "# model.evaluate(x_test, y_cat_test, verbose = 0) ---> Shows the [loss, accuracy]\n",
    "\n",
    "\n",
    "\n",
    "#                           Evaluating using Classification Report & Confusion Matrix\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# predictions = model.predict_classes(x_test)\n",
    "\n",
    "# print(classification_report(y_test,predictions)) ---> Do note that we are no longer using y_cat_test as we should be comparing\n",
    "#                                                       it with the ACTUAL labels\n",
    "#                                                  ---> This compares the True y_test values against the PREDICTED values\n",
    "\n",
    "# confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                 Predicting a Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_number = x_test[0]\n",
    "\n",
    "#plt.imshow(my_number.reshape(28,28)) ---> Need to reshape to the pixels in order to visualise the number\n",
    "\n",
    "# model.predict_classes(my_number.reshape(1,28,28,1)) ---> 1 image, 28 width, 28 height, 1 color channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix and plotting the wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import numpy as np\n",
    "# import itertools\n",
    "\n",
    "# def plot_confusion_matrix(cm, classes,\n",
    "#                           normalize=False,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=plt.cm.Blues):\n",
    "#   \"\"\"\n",
    "#   This function prints and plots the confusion matrix.\n",
    "#   Normalization can be applied by setting `normalize=True`.\n",
    "#   \"\"\"\n",
    "#   if normalize:\n",
    "#       cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#       print(\"Normalized confusion matrix\")\n",
    "#   else:\n",
    "#       print('Confusion matrix, without normalization')\n",
    "\n",
    "#   print(cm)\n",
    "\n",
    "#   plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#   plt.title(title)\n",
    "#   plt.colorbar()\n",
    "#   tick_marks = np.arange(len(classes))\n",
    "#   plt.xticks(tick_marks, classes, rotation=45)\n",
    "#   plt.yticks(tick_marks, classes)\n",
    "\n",
    "#   fmt = '.2f' if normalize else 'd'\n",
    "#   thresh = cm.max() / 2.\n",
    "#   for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#       plt.text(j, i, format(cm[i, j], fmt),\n",
    "#                horizontalalignment=\"center\",\n",
    "#                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#   plt.tight_layout()\n",
    "#   plt.ylabel('True label')\n",
    "#   plt.xlabel('Predicted label')\n",
    "#   plt.show()\n",
    "\n",
    "\n",
    "# p_test = model.predict(x_test).argmax(axis=1)\n",
    "# cm = confusion_matrix(y_test, p_test)\n",
    "# plot_confusion_matrix(cm, list(range(10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show some misclassified examples\n",
    "# misclassified_idx = np.where(p_test != y_test)[0]\n",
    "# i = np.random.choice(misclassified_idx)\n",
    "# plt.imshow(x_test[i], cmap='gray')\n",
    "# plt.title(\"True label: %s Predicted: %s\" % (y_test[i], p_test[i]));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
