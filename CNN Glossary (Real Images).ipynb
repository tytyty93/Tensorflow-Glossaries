{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                         Importing and setting of Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os ---> Imports Operating System\n",
    "\n",
    "# data_dir = 'Copy and Paste the location of the folder' [Example Below]\n",
    "# data_dir = 'C:\\\\Users\\\\Teng Yao\\\\Downloads\\\\TF_2_Notebooks_and_Data\\\\04-CNNs\\\\cell_images'\n",
    "\n",
    "# os.listdir(data_dir) ---> Calls the list directory from the data directory\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from matplotlib.image import imread ---> Allows us to read image files directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                       Setting the Test and Train Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = data_dir + '\\\\ test subfolder\\\\'  ---> Gets the filepath to the test set. \n",
    "#                                               ---> Concatenates the data directory to sub folder and mapping into test_path\n",
    "\n",
    "# train_path = data_dir + '\\\\training subfolder\\\\' ---> Gets the filepath to the training set. \n",
    "#                                                  ---> Concatenates the data directory to sub folder and mapping into training_path\n",
    "\n",
    "# [Do note that these are using the examples from the tutorial, so the directory name will be different for all\n",
    "#  & must format accordingly]\n",
    "\n",
    "\n",
    "# os.listdir(test_path) ---> Lists the files/folders inside the paths\n",
    "# os.listdir(train_path) ---> Lists the files/folders inside the paths\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                  Selecting & displaying only 1 image from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(train_path + 'sub folder 2')[0] ---> Outputs the image name. NOT the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert_variable_name = train_path + 'sub folder 2\\\\' + 'Copy paste the image name.png'\n",
    "# [insert_variable_name will essentially be the entire filepath of a single image]\n",
    "\n",
    "# imread(insert_variable_name) ---> converts the png file into an array\n",
    "\n",
    "# plt.imshow(imread(insert_variable_name)) ---> Shows the image\n",
    "\n",
    "# len(os.listdir(insert_data_path)) ---> Displays the number of images in the folder\n",
    "\n",
    "# Alternatively, we can do:\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# image.load(insert_variable_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                 Resizing the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to resize all the images into the same size or else the CNN won't be able to read it\n",
    "# We should always choose the average of the image size\n",
    "\n",
    "\n",
    "# Step 1: Create two arrays of dimension\n",
    "# dim1 = []\n",
    "# dim2 = []\n",
    "\n",
    "\n",
    "# Step 2: Iterating through each of the image files / Checking the image shape & Saving the dimension\n",
    "# for image_filename in os.listdir(insert_image_directory):\n",
    "#    img = imread(insert_image_directory + image_filename) ---> Do note that the image_filename is not an example, must use this command\n",
    "#    d1,d2,colors = img.shape ---> The img.shape will output dimension1[Width], dimension2[Height], colors[3]\n",
    "#    dim1.append(d1)\n",
    "#    dim2.append(d2)\n",
    "\n",
    "\n",
    "# sns.jointplot(dim1,dim2) ---> Plotting it to see clearer\n",
    "\n",
    "\n",
    "# Step 3: Calculating the mean for dimensions 1 and 2\n",
    "# np.mean(dim1)\n",
    "# np.mean(dim2)\n",
    "\n",
    "\n",
    "# Step 4: This will be the final image shape variable that we will be feeding the CNN with\n",
    "# image_shape = (average_dim1_width,average_dim2_height,3) ---> Input the NUMBERS for the first 2. The 3 is standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                              Manipulating the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# image_gen = ImageDataGenerator(rotation_range = 20, width_shift_range = 0.1, height_shift_range=0.1)\n",
    "#             rotation_range: The amount of degrees we can randomly rotate the images\n",
    "#             width_shift_range: Shifts the actual width of the image by a Maximum Percentage Eg; 0.1 will randomly choose \n",
    "#                                a value between 0% to 10% to shift the width of the image\n",
    "#             height_shift_range: Stretches the actual height of the image by a Maximum Percentage Eg; 0.1 will randomly choose \n",
    "#                                a value between 0% to 10% to shift the height of the image\n",
    "#             rescale = 1/255: We may have to rescale the image if it has not already been normalised for us\n",
    "#             sheer_range = 0.1: Cuts away a percentage of the image. Scales from 0 to 1 [10% from the example]\n",
    "#             zoom_range = 0.1: Randomly zooms in the image. Scales from 0 to 1 [10% from the example]\n",
    "#             horizontal_flip = True: Randomly allow for horizontal flipping\n",
    "#             fill_mode = 'nearest': How to fill in that blank space when we say are stretching the image? Can remain as \n",
    "#                                    blank or some paddings of zeroes. Up to you. We chose nearest in this example.\n",
    "\n",
    "\n",
    "# [For facial data, we shouldn't be adjusting the width and height too much. We also shouldn't rotate 180 degrees if you\n",
    "# are trying to do facial recognition if not what can they do with an upside down face]\n",
    "\n",
    "\n",
    "\n",
    "#                                              Randomizing the image\n",
    "\n",
    "# This will help artificially expand the image\n",
    "\n",
    "# img_variable = imread(img_array) ---> Declaring the image array as a variable\n",
    "# plt.imshow(image_gen.random_transform(para_img)) ---> Displays the image which has been randomised.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#                                Setting up of Directories to flow the batches\n",
    "\n",
    "# image_gen.flow_from_directory(insert_train/test_folder) ---> Do note that the train/test folder path must be in a specific order\n",
    "# [It MUST be in the format of TRAIN/TEST FOLDER --> CLASSIFICATION FOLDER --> Images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers importDense, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(filters=32,kernal_size(3,3), input_shape=image_shape, activation ='relu'))\n",
    "# input_shape: Do note that the image_shape inside here is from the variable declared from Resizing the Image above which is\n",
    "#              basically the mean of all the dimensions of the images in the folder.\n",
    "\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "#=======================================================NOTE================================================================\n",
    "# [Do note that the larger or more complex the image is, you should have more Convulution and Pooling layers like]\n",
    "# [We should also have more filters in the hidden layers as well.]\n",
    "\n",
    "# model.add(Conv2D(filters=32,kernel_size=(3,3), input_shape=image_shape, activation ='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(Conv2D(filters=64,kernel_size=(3,3), input_shape=image_shape, activation ='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    " \n",
    "# model.add(Conv2D(filters=64,kernel_size=(3,3), input_shape=image_shape, activation ='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2,2))) \n",
    "\n",
    "#=============================================================================================================================\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(128,activation='relu'))\n",
    "# model.add(Dropout(0.5)) ---> To prevent Overfitting\n",
    "\n",
    "# model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# model.summary() ---> Optional. Just to see the different layers and density\n",
    "\n",
    "\n",
    "#=======================================================EARLY STOPPING=========================================================\n",
    "\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "\n",
    "\n",
    "#=====================================================TRAINING THE MODEL=======================================================\n",
    "\n",
    "# batch_size = 16 ---> Basically indicates that we are training the model in batches 16 pictures at a time. Usually in powers of 2\n",
    "\n",
    "\n",
    "# train_image_gen = image_gen.flow_from_directory(train_path, target_size = image_shape[:2], \n",
    "#                                                 color_mode='rgb', batch_size=batch_size, class_mode = 'binary')\n",
    "\n",
    "# image_shape[:2]---> If we output image_shape by itself based on the varible declared from above, it will output 130, 130, 3\n",
    "#                     with 3 being the color channels. so by doing [:2], we are just taking the 130, 130 which is the shape only\n",
    "\n",
    "# batch_size ---> As per pre-defined above\n",
    "#            ---> Can also be written as batch_size = 16 without the ''\n",
    "\n",
    "# class_mode = 'binary' ---> Because it is binary classification\n",
    "\n",
    "\n",
    "# test_image_gen = image_gen.flow_from_directory(test_path, target_size = image_shape[:2], \n",
    "#                                                color_mode='rgb', batch_size=batch_size, class_mode = 'binary',\n",
    "#                                                shuffle=False)\n",
    "\n",
    "# shuffle = False: DO NOT SHUFFLE the test images as the labels will also be shuffled around. Only do so for training datasets\n",
    "\n",
    "\n",
    "# train_image_gen.class_indices ---> Reports what 0 represents and 1 represents\n",
    "\n",
    "# results = model.fit_generator(train_image_gen, epochs =20, validation_data=test_image_gen, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                  Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate_generator(test_image_gen) ---> Outputs an array of numbers\n",
    "# model.metrics_name ---> Outputs the names of what the array of numbers are from evaluate_generator\n",
    "\n",
    "# pred = model.predict_generator(test_image_gen) ---> Returns an array [Row:n numbers, Column:1] of the predicted values.\n",
    "#                                                ---> We can define it in a variable like this in pred\n",
    "#                                                ---> It returns probabilities not the actual 1 or 0 integer.\n",
    "\n",
    "# predictions = pred > 0.5 ---> Will convert into an array of True[1 in indices] or False[0 in indices] statements\n",
    "\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# print(classification_report(test_image_gen.classes,predictions)) ---> Compares the actual Y image with it's predictions\n",
    "\n",
    "# confusion_matrix(test_image_gen.classes,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                  Predicting an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can load an image using the step from above which is:\n",
    "\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# my_image = image.load(insert_path_of_image, target_size=image_shape)\n",
    "#target_size ---> Do note that this is basically specifying what the dimensions are for the image. We loaded in image_shape which\n",
    "#                 was pre-defined earlier (130,130)\n",
    "\n",
    "# my_img_arr =  image.img_to_array(my_image) ---> Transforms the image object to an array and assigning it to my_img_arr\n",
    "\n",
    "# my_img_arr = np.expand.dims(my_img_arr, axis=0)\n",
    "#[If we do a my_img_arr.shape, it would have output 130,130,3. BUT, we need to resize it along the 0 dimension as ultimately,\n",
    "# we need the array to output 1,130,130,3 to show that it is 1 image as the model expects batches of images even if it's 1]\n",
    "\n",
    "\n",
    "# model.predict(my_img_arr) ---> Model predicting the image. It will output a 0 or 1.\n",
    "# If you do a train_image_class.class_indices, you will know what the 0 and 1 represents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
