{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.datasets import make_blobs ---> Quickly creating datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = make_blobs(n_samples=300, n_features=2, centers=2, cluster_std=1.0, random_state=101)\n",
    "# n_samples: Number of rows you want in the dataset\n",
    "# n_features: Number of features\n",
    "# centres: Number of clusters\n",
    "# random_state: Just making sure that the samples are the same as the tutorial\n",
    "# [What we just made was 300 samples which is a part of 2 clusters with just 2 features]\n",
    "\n",
    "\n",
    "# X,y = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a Third Feature which is just noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we're doing here is that feature1(X1) & feature2(X2) has something which in the end will result in the labels being\n",
    "# 1 or 0.\n",
    "# We then add another feature(X3) which has no correlation to cause the label to be 1 or 0\n",
    "\n",
    "# np.random.seed(seed=101)\n",
    "# z_noise = np.random.normal(size=len(X))\n",
    "# z_noise = pd.Series(z_noise)\n",
    "\n",
    "# feat = pd.DataFrame(X)\n",
    "# feat = pd.concat([feat,z_noise],axis=1)\n",
    "# feat.columns = ['X1','X2','X3']\n",
    "# feat.head()\n",
    "\n",
    "# plt.scatter(feat['X1'], feat['X2'], c=y) ---> You can clearly see that X1 and X2 clusters are seperated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can go https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html#scatter-plots to get the codes to make different 3D plots\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# %matplotlib notebook ---> Making it an interactive plot(Optional)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection = '3d')\n",
    "# ax.scatter(feat['X1'],feat['X2'],feat['X3'],c=y)\n",
    "\n",
    "# If you look using the interactive plot, you can see that the 3rd feature only adds noise and does not seperate them out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Creating Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.optimizers import SGD ---> Importing Stochastic Gradient Descent\n",
    "\n",
    "# What we're going to do now is to create 3 inputs, reduce it down to 2 neurons in the hidden layer and expand it back\n",
    "\n",
    "# encoder = Sequential()\n",
    "# encoder.add(Dense(units=2, activation='relu', input_shape=[3]))\n",
    "# [The input shape goes in as 3 and outputs as 2 which explains the units=2]\n",
    "\n",
    "# decoder = Sequential()\n",
    "# decoder.add(Dense(units=3, activation='relu', input_shape=[2]))\n",
    "# [The input shape goes in as 2 and outputs as 3 which explains the units=3]\n",
    "\n",
    "# autoencoder = Sequential([encoder,decoder]) ---> Combining them together\n",
    "\n",
    "# autoencoder.compile(loss='mse', optimizer=SGD(lr=1.5))\n",
    "# loss = 'mse': As they are continuous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Scaling the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_data = scaler.fit_transform(feat) ---> Doesn't make sense for doing something that we actually don't know the correct\n",
    "#                                               Answer to. So we just fit_transform the whole features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Training & Encoder Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then train the auto encoder together so that the encoder can learn the best way to reduce from 3 to 2 neurons in order to\n",
    "# re-produce a similar output on the decoder side \n",
    "\n",
    "# autoencoder.fit(scaled_data, scaled_data, epochs = 5)\n",
    "\n",
    "# encoded_2dim = encoder.predict(scaled_data) ---> Only grabbing the encoder section and asking it to predict based off the\n",
    "#                                                  scaled data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Visualizing the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_2dim.shape ---> Notice it takes from the shape of (300,3) in this example to (300,2)\n",
    "\n",
    "# plt.scatter(encoded_2dim[:,0],encoded_2dim[:,1], c=y) ---> Grabbing all the rows from first column and plotting \n",
    "#                                                            against the second"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
