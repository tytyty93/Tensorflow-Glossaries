{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background\n",
    "\n",
    "# CIFAR-10 dataset are 32by32 images of 10 different objects: Airplane, Car, Bird, Cat, Deer, Dog, Frog, Horse, Ship, Truck\n",
    "# Each classes have 6000 images making the total images of CIFAR-10 60000 images\n",
    "# They are color images\n",
    "# 90% of codes are the same as the MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                     Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# x_train.shape ---> Will display (50000,32,32,3): 50000 images, 32 by 32 pixels and 3 color channels(RGB)\n",
    "\n",
    "# x_train[0].shape ---> Outputs (32,32,3): this image at position[0] is 32 by 32 pixels with 3 color channels\n",
    "\n",
    "#plt.imshow(x_train[0]) ---> Shows the image of a frog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                   Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train/255\n",
    "# x_test = x_test/255\n",
    "# [Since the maximum value is 255, we can normalise it by division]\n",
    "\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# y_cat_train = to_categorical(y_train,10)\n",
    "# y_cat_test = to_categorical(y_test,10)\n",
    "# [Since y_train are just labels by integer, we do not want it to be read as continuous value but categorical value instead]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Sequential and Dense\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "#                                                [Convolution Layer]\n",
    "\n",
    "# model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))\n",
    "\n",
    "# Filters: The larger the image, the larger the filter should be. Should be in powers of 2s.\n",
    "\n",
    "# Kernal_size: Typical sizes are 2 by 2 or 4 by 4\n",
    "\n",
    "# Strides: How many pixels do you want to move the kernal, for larger images, should have bigger strides\n",
    "\n",
    "# Padding='valid': Applied by default. Doesn't apply any padding. If the kernal size fits perfectly with the image pixels \n",
    "#                    and the strides, there is no need  for it. Eg; 28pixels image divided by 4x4 kernal \n",
    "#                    gives integer so can set as valid  \n",
    "\n",
    "# Padding='same': Automatically figures out what the padding should be so that the image gets fully covered by \n",
    "#                    the filter and stride. Ensures that the output size is the same as input.\n",
    "\n",
    "# Input shape: The shape of a single image\n",
    "\n",
    "\n",
    "\n",
    "#                                                  [Pooling Layer]\n",
    "\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# [Since there are a lot more information within the color images, we should add in more Convolution & Pooling layers]\n",
    "# [Can increase the filters as well]\n",
    "\n",
    "\n",
    "\n",
    "#                                               [Flattening the image]\n",
    "# model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "#                                      Adding the Dense Layer & Output Neurons\n",
    "\n",
    "# model.add(Dense(256, activation = 'relu'))--->Should more or less match the same scale as the flattened unit and in powers of 2\n",
    "# model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#                                                    [Compile]\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# [It's nice to have the accuracy inside as we can't really tell from the loss]\n",
    "\n",
    "\n",
    "#                                             [Adding Early Stopping]\n",
    "\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience = 2)\n",
    "\n",
    "\n",
    "\n",
    "#                                                [Fitting the Model] \n",
    "# model.fit(x_train, y_cat_train, epochs=15, validation_data=(x_test, y_cat_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = pd.DataFrame(model.history.history)\n",
    "# metrics ---> This will output the loss, accuracy, val_loss, val_accuracy based on the example above\n",
    "\n",
    "\n",
    "# metrics[['loss', 'val_loss']].plot() ---> Plots the loss against val_loss\n",
    "# metrics[['accuracy', 'val_accuracy']].plot() ---> Plots the accuracy against val_accuracy\n",
    "\n",
    "# model.evaluate(x_test, y_cat_test, verbose = 0) ---> Shows the [loss, accuracy]\n",
    "\n",
    "\n",
    "\n",
    "#                           [Evaluating using Classification Report & Confusion Matrix]\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# predictions = model.predict_classes(x_test)\n",
    "\n",
    "# print(classification_report(y_test,predictions)) ---> Do note that we are no longer using y_cat_test as we should be comparing\n",
    "#                                                       it with the ACTUAL labels\n",
    "#                                                  ---> This compares the True y_test values against the PREDICTED values\n",
    "\n",
    "# confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                           Predicting a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_image = x_test[0]\n",
    "\n",
    "# plt.imshow(my_image)\n",
    " \n",
    "# model.predict_classes(my_image.reshape(1,32,32,3)) ---> 1 image, 28 width, 28 height, 1 color channel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
